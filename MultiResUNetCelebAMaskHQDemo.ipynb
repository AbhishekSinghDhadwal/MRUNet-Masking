{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiResUNetCelebAMaskHQDemo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAyfvkW_FzfO",
        "colab_type": "text"
      },
      "source": [
        "# **Demos of MultiResUNet models implemented on the CelebAMaskHQ dataset**\n",
        "In this notebook, we display demos of the models tested using the mechanisms mentioned in [MultiResUNet.ipynb](https://drive.google.com/file/d/1H26uaN10rU2V7MnX8vRdE3J0ZMoO7wq2/view?usp=sharing).\n",
        "This demo should work irrespective of any access issues to the author's drive.\n",
        "If any errors in downloading models may occur, kindly notify me.\n",
        "\n",
        "We use gdown to install the JSON files (per model) and their weights for testing, and user input image is utilised in order to provide output.\n",
        "\n",
        "Note : Due to Colab's anomalous nature with matplotlib.pyplot, we will store the final images within the machine.\n",
        "\n",
        "PS : If you would like to see the results for all the demo networks, utilise the 'Run All' feature in the Runtime submenu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5vPReDGIX5w",
        "colab_type": "text"
      },
      "source": [
        "Run the snippet below in order to download all the models and their corresponding weights:\n",
        "\n",
        "You can download the models by going through the links mentioned in the comments below-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rll2SEOUs4G-",
        "colab_type": "code",
        "outputId": "a452d0ac-fb84-4ad0-c857-f9e84511a808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
        "from keras.models import Model, model_from_json\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import backend as K \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "!pip install gdown\n",
        "\n",
        "# The testing model -\n",
        "# https://drive.google.com/file/d/1-0H74nlLkTnnvSkMG-MPuhuX70LXBOlo/view?usp=sharing\n",
        "# https://drive.google.com/file/d/1--fVnHrfDpujmdX9OWT6PVmNQjQ1mPX8/view?usp=sharing\n",
        "\n",
        "# The F10k model -\n",
        "# https://drive.google.com/file/d/1-GhqkzttGHAkGi0r5XEgowVg8wLcgmY1/view?usp=sharing\n",
        "# https://drive.google.com/file/d/1-CPthO3qPHE_IeykqyG_bndf9UuQbHAO/view?usp=sharing\n",
        "\n",
        "# The FD10 model -\n",
        "# https://drive.google.com/file/d/1yhWML6lThGv_MSGkUOuVhkoD7H-u6gwm/view?usp=sharing\n",
        "# https://drive.google.com/file/d/12S277zHGFN9YPKcX7M7hEwxkokvT5bNt/view?usp=sharing\n",
        "\n",
        "# For the test model :\n",
        "!gdown --id 1-0H74nlLkTnnvSkMG-MPuhuX70LXBOlo --output modelP5.json\n",
        "!gdown --id 1--fVnHrfDpujmdX9OWT6PVmNQjQ1mPX8 --output modelW.h5\n",
        "\n",
        "# For the F10k model :\n",
        "!gdown --id 1-GhqkzttGHAkGi0r5XEgowVg8wLcgmY1 --output modelP5f10.json\n",
        "!gdown --id 1-CPthO3qPHE_IeykqyG_bndf9UuQbHAO --output modelWf10.h5\n",
        "\n",
        "# For the FD10 model :\n",
        "!gdown --id 1yhWML6lThGv_MSGkUOuVhkoD7H-u6gwm --output modelP5FD.json\n",
        "!gdown --id 12S277zHGFN9YPKcX7M7hEwxkokvT5bNt --output modelWFD.h5\n",
        "\n",
        "\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.8)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-0H74nlLkTnnvSkMG-MPuhuX70LXBOlo\n",
            "To: /content/modelP5.json\n",
            "100% 117k/117k [00:00<00:00, 35.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1--fVnHrfDpujmdX9OWT6PVmNQjQ1mPX8\n",
            "To: /content/modelW.h5\n",
            "29.6MB [00:00, 57.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-GhqkzttGHAkGi0r5XEgowVg8wLcgmY1\n",
            "To: /content/modelP5f10.json\n",
            "100% 117k/117k [00:00<00:00, 42.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-CPthO3qPHE_IeykqyG_bndf9UuQbHAO\n",
            "To: /content/modelWf10.h5\n",
            "29.6MB [00:00, 138MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yhWML6lThGv_MSGkUOuVhkoD7H-u6gwm\n",
            "To: /content/modelP5FD.json\n",
            "100% 117k/117k [00:00<00:00, 35.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12S277zHGFN9YPKcX7M7hEwxkokvT5bNt\n",
            "To: /content/modelWFD.h5\n",
            "29.6MB [00:00, 181MB/s]\n",
            "15000.jpg\t modelP5FD.json  modelWFD.h5\t     results_modelP5FD\n",
            "29987.jpg\t modelP5.json\t modelW.h5\t     sample_data\n",
            "modelP5f10.json  modelWf10.h5\t results_modelP5f10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "worLfpshRBF6",
        "colab_type": "text"
      },
      "source": [
        "### Image input and pre processing :\n",
        "Run the cell below in order to \n",
        "upload the required images to be tested.\n",
        "Accepts .jpg format images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7sTn14gRBla",
        "colab_type": "code",
        "outputId": "e7b10f9e-e019-41d5-ebe0-b1664a511e2a",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "img_arr = []\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "    \n",
        "    if(fn.split('.')[-1]=='jpg'or fn.split('.')[-1]=='jpeg'):\n",
        "        img = cv2.imread(fn, cv2.IMREAD_COLOR)\n",
        "        img_arr.append(cv2.resize(img,(256, 192), interpolation = cv2.INTER_CUBIC))\n",
        "    else:\n",
        "        print(fn+' is not of the valid format.')\n",
        "img_loaded = img_arr\n",
        "img_arr = np.array(img_arr)        \n",
        "img_arr = img_arr / 255\n",
        "print('Number of images uploaded : '+str(len(img_arr)))\n",
        "img_names = list(uploaded.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4cf3e1c1-e7fa-4a7d-b87a-cb9086824b02\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4cf3e1c1-e7fa-4a7d-b87a-cb9086824b02\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 29987.jpg to 29987 (1).jpg\n",
            "Saving 29978.jpg to 29978.jpg\n",
            "User uploaded file \"29987.jpg\" with length 55367 bytes\n",
            "User uploaded file \"29978.jpg\" with length 65300 bytes\n",
            "Number of images uploaded : 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzZ7eE79PARZ",
        "colab_type": "text"
      },
      "source": [
        "## Boilerplate code to run model :\n",
        "This code provides outputs in the format(image-mask-imagewithmask).\n",
        "\n",
        "Your results will be stored under the Files Section (on the left side of the website) in the folder specified by the output during runtime.\n",
        "\n",
        "In order to allow for automatic downloading of the images, just uncomment the\n",
        "```\n",
        "#files.download('results_'+model_json.split('.')[0]+'/result_'+str(img_names[i].split('.')[0])+'.png')\n",
        "```\n",
        "section of the code below. \n",
        "(NOTE : This feature works only for **Google Chrome** users)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWnaPyKlPs4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from keras.models import model_from_json\n",
        "\n",
        "def RunModel( model_json, model_weights, image_array, img_names, img_loaded):\n",
        "\n",
        "    try:\n",
        "        os.makedirs('results_'+model_json.split('.')[0])\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    print('Your results will be stored under the Files Section in the folder '+'results_'+model_json.split('.')[0])\n",
        "    # load json and create model\n",
        "    json_file = open(model_json, 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    \n",
        "    # load weights into new model\n",
        "    loaded_model.load_weights(model_weights)\n",
        "    print(\"Loaded model from disk\")\n",
        "    loaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    # Used in order to ease naming\n",
        "    i = 0\n",
        "    yp = loaded_model.predict(x=np.array(image_array), batch_size=1, verbose=1)\n",
        "    yp = np.round(yp,0)\n",
        "    \n",
        "    for ip_img in image_array:\n",
        "        \n",
        "        # Modification of mask in order to mimic sample output \n",
        "        t = yp[i]\n",
        "        a = np.concatenate((t,t),axis = 2)\n",
        "        b = np.concatenate((a,t),axis = 2)\n",
        "        b = b * 255\n",
        "        \n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.imshow(cv2.cvtColor(np.array(img_loaded[i]), cv2.COLOR_BGR2RGB))\n",
        "        plt.title('Input')\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
        "        plt.title('Prediction')\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.imshow(cv2.cvtColor(cv2.addWeighted(np.uint8(img_loaded[i]), 0.5, np.uint8(b), 0.5, 0.0),cv2.COLOR_BGR2RGB))\n",
        "        plt.title('Prediction with mask')\n",
        "        plt.savefig('results_'+model_json.split('.')[0]+'/result_'+str(img_names[i].split('.')[0])+'.png',format='png')\n",
        "        plt.close()\n",
        "        # Uncomment the line below to allow automatic downloading\n",
        "        #files.download('results_'+model_json.split('.')[0]+'/result_'+str(img_names[i].split('.')[0])+'.png')\n",
        "        i += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryIe_uyV2HIv",
        "colab_type": "text"
      },
      "source": [
        "# **Model F10k:**\n",
        "This model has been trained on a 80%-20% split amongst the first 10,000 images of the dataset.\n",
        "\n",
        "*   Number of epochs: 20\n",
        "*   Time taken : [1:29:40, 267.74s/it]\n",
        "*   Jacard Index(final) : 0.8452393049122288\n",
        "*   Dice Coefficient(final) : 0.9139967587791317\n",
        "*   Accuracy(final) : 99.80 %"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_VYaY1XyhQz_",
        "outputId": "21ebf1b4-81c7-4e64-bdc9-6bf38d656ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "RunModel('modelP5f10.json','modelWf10.h5', img_arr, img_names, img_loaded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your results will be stored under the Files Section in the folder results_modelP5f10\n",
            "Loaded model from disk\n",
            "2/2 [==============================] - 5s 3s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hERoEDhmsAx",
        "colab_type": "text"
      },
      "source": [
        "# **Model FD10:**\n",
        "\n",
        "The dataset for this model has been split twice: \n",
        "\n",
        "1. Three sets of 10,000 images each.\n",
        "2. Each set trained on a 80%-20% split.\n",
        "\n",
        "Each split of the data was used to train the model for 10 epochs each. The split was performed in order to compensate for RAM bottlenecks in our system. \n",
        "\n",
        "*   Number of epochs: 10+10+10 = 30\n",
        "*   Time taken : [2:29:04, 2958.94s/it]\n",
        "*   Jacard Index(final) : 0.8331437322988224\n",
        "*   Dice Coefficient(final) : 0.9071035040844939\n",
        "*   Accuracy(final) : 99.70 %"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OOKELrrms4P",
        "colab_type": "code",
        "outputId": "657801ec-9eb6-48a7-f5ab-68b640b55469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "RunModel('modelP5FD.json','modelWFD.h5',img_arr,img_names,img_loaded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your results will be stored under the Files Section in the folder results_modelP5FD\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Loaded model from disk\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2/2 [==============================] - 4s 2s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43O6SFo3mt3x",
        "colab_type": "text"
      },
      "source": [
        "# **EXTRA : Base Testing Model**\n",
        "\n",
        "**This model returns only the left eye segmented as a mask and was made for TESTING PURPOSES ONLY**\n",
        "\n",
        "This model has been trained on a 80%-20% split amongst the first 250 images of the dataset, and was used in order to test the original model mentioned in the paper.\n",
        "\n",
        "*   Number of epochs: 10\n",
        "*   Time taken : [0:20:40]\n",
        "*   Jacard Index(final) : 0.39899180087352404\n",
        "*   Dice Coefficient(final) : 0.495551362130639337\n",
        "*   Accuracy(final) : 99.80 %\n",
        "\n",
        "**NOTE : THIS MODEL IS SIMPLY A PRECURSOR TO OUR ACTUAL MODELS MENTIONED ABOVE AND SHOULD NOT BE CONSIDERED AS FEASIBLE FOR ANY ASPECTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZzHvPnemwgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RunModel('modelP5.json','modelW.h5',img_arr,img_names,img_loaded)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}