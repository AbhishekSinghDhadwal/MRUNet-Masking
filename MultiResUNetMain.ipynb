{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MultiResUNetMain.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SKD7jSvIn1T9"
      },
      "source": [
        "# Importing Modules\n",
        "\n",
        "The necessary modules are : os, opencv, numpy, tqdm, matplotlib, keras and sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nNtz_YYVnzcZ",
        "outputId": "e19dc3af-5bb5-4f77-d8f2-4f7ddf9ab87a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
        "from keras.models import Model, model_from_json\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import backend as K \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xLkeS7Lxo_Po"
      },
      "source": [
        "# Constructing Training and Test Datasets\n",
        "\n",
        "We first load our images from Google Drive, and change directories for future operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhiI90AdSecr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir(\"/content/drive/My Drive/CelebAMaskHQ/\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gHo6ymwFpJzY"
      },
      "source": [
        "## Loading the Images\n",
        "\n",
        "We first load all the images and the corresponding segmentation masks.\n",
        "\n",
        "**Kindly store your data in the following format inside your CelebAMaskHQ folder:**\n",
        "- All the original images in the 'images' folder\n",
        "- The left eye masks in the 'l_eye' folder\n",
        "- The right eye masks in the 'r_eye' folder\n",
        "- The lower lip masks in the 'l_lip' folder\n",
        "- The upper lip masks in the 'u_lip' folder\n",
        "\n",
        "For image '0.jpg', the left eye mask should be '0_l_eye.png' and stored in the l_eye folder, the right eye mask should be '0_r_eye.png' and stored in the r_eye folder, the lower lip mask should be '0_l_lip.png' and stored in the l_lip folder, the upper lip mask should be '0_u_lip.png' and stored in the u_lip folder.\n",
        "\n",
        "\n",
        "In order to format the images in the manner provided, just paste the images in their corresponding folders, and run the “EXTRA : Pre processing of input files” section at the bottom of the notebook. The code snippet will do the rest.\n",
        "\n",
        "They are stored in two lists X, Y and respectively\n",
        "\n",
        "Moreover, the images are resized to 256x192\n",
        "\n",
        "\n",
        "NOTE : In colab, StopIteration errors will occur in the start. The errors are caused by Drive timeouts, and will be handled themselves after repeated running due to increase of data stored in our cache."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YbeQ1aytHTm3",
        "colab": {}
      },
      "source": [
        "img_files = next(os.walk('images/'))[2]\n",
        "leye_files = next(os.walk('l_eye/'))[2]\n",
        "reye_files = next(os.walk('r_eye/'))[2]\n",
        "llip_files = next(os.walk('l_lip/'))[2]\n",
        "ulip_files = next(os.walk('u_lip/'))[2]\n",
        "\n",
        "# Used to display the differences between the number of masks available\n",
        "# For each folder\n",
        "print(len(img_files))\n",
        "print(len(leye_files))\n",
        "print(len(reye_files))\n",
        "print(len(llip_files))\n",
        "print(len(ulip_files))\n",
        "\n",
        "# We create a checkpoint mechanism in order to compensate for\n",
        "# Google's 12 hour runtime restrictions. It stores the arrays after\n",
        "# every 2000 iterations, and will load them each time we run our data\n",
        "try:\n",
        "    X = np.load('X.npy')\n",
        "    Y = np.load('Y.npy')\n",
        "    i = np.load('i.npy')\n",
        "    count = np.load('count.npy')\n",
        "except IOError:\n",
        "    X = []\n",
        "    Y = []\n",
        "    i = 0\n",
        "    count = 0\n",
        "\n",
        "pbar = tqdm(total = 30000-i)\n",
        "while(i < 30000):    \n",
        "    img_f1 = \"/content/drive/My Drive/CelebAMaskHQ/images/\"+str(i)+\".jpg\"\n",
        "    if(os.path.exists(img_f1)):\n",
        "        print(\"Image \"+img_f1+\" exists\")\n",
        "        if(os.path.exists('/content/drive/My Drive/CelebAMaskHQ/l_eye/'+str(i)+'_l_eye.png') and os.path.exists('/content/drive/My Drive/CelebAMaskHQ/r_eye/'+str(i)+'_r_eye.png') and os.path.exists('/content/drive/My Drive/CelebAMaskHQ/l_lip/'+str(i)+'_l_lip.png') and os.path.exists('/content/drive/My Drive/CelebAMaskHQ/u_lip/'+str(i)+'_u_lip.png') ):                \n",
        "            \n",
        "            # NOTE : The above if case is made in order to compensate for incomplete data\n",
        "            # i.e there is a lack of masks for certain images, as noted by the \n",
        "            # difference of number of file objects per mask in the dataset\n",
        "\n",
        "            # Taking main image as input and resizing\n",
        "            img = cv2.imread('images/'+str(i)+'.jpg', cv2.IMREAD_COLOR)\n",
        "            resized_img = cv2.resize(img,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "        \n",
        "            X.append(resized_img)\n",
        "            # We are reading each and every mask available\n",
        "            # In accordance to the dataset provided\n",
        "            leye = cv2.imread('l_eye/{}'.format(str(i)+'_l_eye.png'), cv2.IMREAD_GRAYSCALE)\n",
        "            reye = cv2.imread('r_eye/{}'.format(str(i)+'_r_eye.png'), cv2.IMREAD_GRAYSCALE)\n",
        "            llip = cv2.imread('l_lip/{}'.format(str(i)+'_l_lip.png'), cv2.IMREAD_GRAYSCALE)\n",
        "            ulip = cv2.imread('u_lip/{}'.format(str(i)+'_u_lip.png'), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # We resize our data to fit params of MultiResUNet\n",
        "            resized_leye = cv2.resize(leye,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "            resized_reye = cv2.resize(reye,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "            resized_llip = cv2.resize(llip,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "            resized_ulip = cv2.resize(ulip,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "            # The below statements combine all the four masks into one picture\n",
        "            # In order to satisfy question requirements(preprocessing)\n",
        "            op = np.maximum(np.array(resized_leye),np.array(resized_reye))\n",
        "            op = np.maximum(op, np.array(resized_llip))\n",
        "            op = np.maximum(op,np.array(resized_ulip))\n",
        "\n",
        "            count += 1\n",
        "            Y.append(op)\n",
        "            pbar.update(1)\n",
        "            print(\"Picture \"+str(i)+\" is valid\")\n",
        "\n",
        "        i += 1\n",
        "        print(\"Iteration \"+str(i)+\" complete\")\n",
        "        \n",
        "        # Aids in checkpointing data, overwrites after every 2000 iters \n",
        "        # To protect against runtime issues\n",
        "        if(i % 2000 == 0):\n",
        "            np.save('X',X)\n",
        "            np.save('Y',Y)\n",
        "            np.save('i',i)\n",
        "            np.save('count',count)\n",
        "\n",
        "print(\"The number of valid images(images entered) : \"+str(count))        \n",
        "\n",
        "# Saving arrays after completion of loop\n",
        "np.save('X',X)\n",
        "np.save('Y',Y)\n",
        "np.save('i',i)\n",
        "np.save('count',count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY8CGVPqoEt-",
        "colab_type": "text"
      },
      "source": [
        "#Run in order to derive data from original parsing method :\n",
        "\n",
        "NOTE - In order to compensate for time and handle the parsing process within colab, I had originally divided the dataset into 3 parts, and ran 3 different notebooks simultaneously across the datasets for faster pre processing.\n",
        "\n",
        "The links to the original (workaround) notebooks are provided below :\n",
        "\n",
        "https://colab.research.google.com/drive/1xz2f6bkIe7HQG5TAKSxdThYj7DrquULF\n",
        "\n",
        "https://colab.research.google.com/drive/19Q_rWBzq8Jy7zdJCiz1xIVbaw8JVAyq9\n",
        "\n",
        "https://colab.research.google.com/drive/13zogbjdIvnSFygFAxuosUsl0yFrgS_Yr\n",
        "\n",
        "Or, alternatively check the /workaround section of the repository.\n",
        "\n",
        "**In order to attain the split, just run the notebooks mentioned above, the resulting numpy arrays will be stored in your drive automatically.**\n",
        "\n",
        "\n",
        "PS: This section may require a high RAM runtime implementation of the notebook. Colab may crash and reallocate resources automatically.\n",
        "In order to accomodate the size of the dataset, we only use the first 20,000 images extracted.\n",
        "In order to use the whole extracted dataset, just uncomment the sections involving X3 and Y3\n",
        "\n",
        "In order to further ease access of resources, do not run the following code and check out the 'improved' sub-section of our 'Define Model, Train, Evaluate' part of the notebook. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci5GhKXUoFke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading our arrays\n",
        "X1 = np.load('X1.npy')\n",
        "X2 = np.load('X2.npy')\n",
        "#X3 = np.load('X3.npy')\n",
        "\n",
        "Y1 = np.load('Y1.npy')\n",
        "Y2 = np.load('Y2.npy')\n",
        "#Y3 = np.load('Y3.npy')\n",
        "\n",
        "# Printing array shapes for confirmation\n",
        "print(X1.shape)\n",
        "print(X2.shape)\n",
        "#print(X3.shape)\n",
        "print(Y1.shape)\n",
        "print(Y2.shape)\n",
        "#print(Y3.shape)\n",
        "\n",
        "# We use the append function with axis=0 in order to preserve the\n",
        "# original shape of the arrays\n",
        "X = np.append(X1,X2,axis=0)\n",
        "#X = np.append(X,X3,axis=0)\n",
        "\n",
        "Y = np.append(Y1,Y2,axis=0)\n",
        "#Y = np.append(Y,Y3,axis=0)\n",
        "\n",
        "# NOTE : The first dimension of both the arrays should be the same\n",
        "# Else data may be corrupted/contaminated\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "#Saving arrays for future use\n",
        "np.save('X',X)\n",
        "np.save('Y',Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jYgEz9HQpgsR"
      },
      "source": [
        "## Train-Test Split\n",
        "\n",
        "The X, Y lists are converted to numpy arrays for convenience. \n",
        "Furthermore, the images are divided by 255 to bring down the pixel values to [0...1] range. On the other hand the segmentations masks are converted to binary (0 or 1) values.\n",
        "\n",
        "Using Sklearn *train_test_split* we split the data randomly into 80% training and 20% testing data\n",
        "\n",
        "NOTE: Due to colab's constraints, we are using the first ten thousand images only.\n",
        "\n",
        "In order to use the first twenty thousand processed images, run the above code snippet and comment out the lines involving X3 and Y3 (if they are not commented out already) ,then, for the snippet below, replace 'X1.npy' with 'X.npy' in the first line, and replace 'Y1.npy' with 'Y.npy'\n",
        "\n",
        "In order to use ALL the processed images:\n",
        "\n",
        "(if using pre processed data from the parallely ran programs)\n",
        "Follow the above step and make the changes required in the above code snippet \n",
        "\n",
        "Else you simply replace 'X1.npy' with 'X.npy' in the first line, and replace 'Y1.npy' with 'Y.npy'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CxFIZv3715Dt",
        "colab": {}
      },
      "source": [
        "def LoadData(xloc='X1.npy', yloc='Y1.npy'):\n",
        "    X = np.load(xloc)\n",
        "    Y = np.load(yloc)\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
        "\n",
        "    Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],Y_train.shape[2],1))\n",
        "    Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],Y_test.shape[2],1))\n",
        "\n",
        "    X_train = X_train / 255\n",
        "    X_test = X_test / 255\n",
        "    Y_train = Y_train / 255\n",
        "    Y_test = Y_test / 255\n",
        "\n",
        "    Y_train = np.round(Y_train,0)\t\n",
        "    Y_test = np.round(Y_test,0)\t\n",
        "\n",
        "    print(X_train.shape)\n",
        "    print(Y_train.shape)\n",
        "    print(X_test.shape)\n",
        "    print(Y_test.shape)\n",
        "    return X_train,Y_train,X_test,Y_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C-Ajp2QVrMti"
      },
      "source": [
        "# MultiResUNet Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "21cbmiojrYrU"
      },
      "source": [
        "## Model Definition\n",
        "\n",
        "The MultiResUNet model as described in the [paper](https://arxiv.org/abs/1902.04049) can be found  [here](https://github.com/nibtehaz/MultiResUNet/blob/master/MultiResUNet.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2nX7I1Wf_zEy",
        "colab": {}
      },
      "source": [
        "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
        "    '''\n",
        "    2D Convolutional layers\n",
        "    \n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer \n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "    \n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
        "        activation {str} -- activation function (default: {'relu'})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "    \n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "    if(activation == None):\n",
        "        return x\n",
        "\n",
        "    x = Activation(activation, name=name)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
        "    '''\n",
        "    2D Transposed Convolutional layers\n",
        "    \n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer \n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "    \n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "    \n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "def MultiResBlock(U, inp, alpha = 1.67):\n",
        "    '''\n",
        "    MultiRes Block\n",
        "    \n",
        "    Arguments:\n",
        "        U {int} -- Number of filters in a corrsponding UNet stage\n",
        "        inp {keras layer} -- input layer \n",
        "    \n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    W = alpha * U\n",
        "\n",
        "    shortcut = inp\n",
        "\n",
        "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
        "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
        "\n",
        "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def ResPath(filters, length, inp):\n",
        "    '''\n",
        "    ResPath\n",
        "    \n",
        "    Arguments:\n",
        "        filters {int} -- [description]\n",
        "        length {int} -- length of ResPath\n",
        "        inp {keras layer} -- input layer \n",
        "    \n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "\n",
        "    shortcut = inp\n",
        "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                         activation=None, padding='same')\n",
        "\n",
        "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    for i in range(length-1):\n",
        "\n",
        "        shortcut = out\n",
        "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                             activation=None, padding='same')\n",
        "\n",
        "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "        out = add([shortcut, out])\n",
        "        out = Activation('relu')(out)\n",
        "        out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def MultiResUnet(height, width, n_channels):\n",
        "    '''\n",
        "    MultiResUNet\n",
        "    \n",
        "    Arguments:\n",
        "        height {int} -- height of image \n",
        "        width {int} -- width of image \n",
        "        n_channels {int} -- number of channels in image\n",
        "    \n",
        "    Returns:\n",
        "        [keras model] -- MultiResUNet model\n",
        "    '''\n",
        "\n",
        "\n",
        "    inputs = Input((height, width, n_channels))\n",
        "\n",
        "    mresblock1 = MultiResBlock(32, inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
        "    mresblock1 = ResPath(32, 4, mresblock1)\n",
        "\n",
        "    mresblock2 = MultiResBlock(32*2, pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
        "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
        "\n",
        "    mresblock3 = MultiResBlock(32*4, pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
        "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
        "\n",
        "    mresblock4 = MultiResBlock(32*8, pool3)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
        "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
        "\n",
        "    mresblock5 = MultiResBlock(32*16, pool4)\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(\n",
        "        32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
        "    mresblock6 = MultiResBlock(32*8, up6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(\n",
        "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
        "    mresblock7 = MultiResBlock(32*4, up7)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(\n",
        "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
        "    mresblock8 = MultiResBlock(32*2, up8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(\n",
        "        2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
        "    mresblock9 = MultiResBlock(32, up9)\n",
        "\n",
        "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')\n",
        "    \n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2frZlpmFsv1f"
      },
      "source": [
        "## Auxiliary Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "degBGBWYsyNG"
      },
      "source": [
        "### Custom Metrics\n",
        "\n",
        "Since Keras does not have build-in support for computing Dice Coefficient or Jaccard Index (at the time of writing), the following functions are declared"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xq8qfLqDA6q2",
        "colab": {}
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 0.0\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def jacard(y_true, y_pred):\n",
        "\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum ( y_true_f * y_pred_f)\n",
        "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "\n",
        "    return intersection/union"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VtvyeBXy8Mk3"
      },
      "source": [
        "### Saving Model \n",
        "\n",
        "Function to save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GCfX9MUYALar",
        "colab": {}
      },
      "source": [
        "def saveModel(model):\n",
        "\n",
        "    model_json = model.to_json()\n",
        "\n",
        "    try:\n",
        "        os.makedirs('models')\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    fp = open('models/modelP5A.json','w')\n",
        "    fp.write(model_json)\n",
        "    model.save_weights('models/modelWA.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AH3znjx-8vDq"
      },
      "source": [
        "### Evaluate the Model\n",
        "\n",
        "We evaluate the model on test data (X_test, Y_test). \n",
        "\n",
        "We compute the values of Jaccard Index and Dice Coeficient, and save the predicted segmentation of first 10 images. The best model is also saved\n",
        "\n",
        "(This could have been done using keras call-backs as well)\n",
        "\n",
        "**NOTE : The files saved using this method do not follow the format specified in the task. For proper input and output specifications, kindly refer to the Demonstrations linked at the bottom of this book.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tkit_YYvBQ7V",
        "colab": {}
      },
      "source": [
        "def evaluateModel(model, X_test, Y_test, batchSize):\n",
        "    \n",
        "    try:\n",
        "        os.makedirs('results')\n",
        "    except:\n",
        "        pass \n",
        "    \n",
        "\n",
        "    yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
        "\n",
        "    yp = np.round(yp,0)\n",
        "\n",
        "    for i in range(10):\n",
        "\n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.imshow(np.array(X_test[i]))\n",
        "        plt.title('Input')\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.imshow(Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1]))\n",
        "        plt.title('Ground Truth')\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
        "        plt.title('Prediction')\n",
        "\n",
        "        intersection = yp[i].ravel() * Y_test[i].ravel()\n",
        "        union = yp[i].ravel() + Y_test[i].ravel() - intersection\n",
        "\n",
        "        jacard = (np.sum(intersection)/np.sum(union))  \n",
        "        plt.suptitle('Jacard Index'+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +'='+str(jacard))\n",
        "\n",
        "        plt.savefig('results/'+str(i)+'fdbl.png',format='png')\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "    jacard = 0\n",
        "    dice = 0\n",
        "    \n",
        "    \n",
        "    for i in range(len(Y_test)):\n",
        "        yp_2 = yp[i].ravel()\n",
        "        y2 = Y_test[i].ravel()\n",
        "        \n",
        "        intersection = yp_2 * y2\n",
        "        union = yp_2 + y2 - intersection\n",
        "\n",
        "        jacard += (np.sum(intersection)/np.sum(union))  \n",
        "\n",
        "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
        "\n",
        "    \n",
        "    jacard /= len(Y_test)\n",
        "    dice /= len(Y_test)\n",
        "    \n",
        "\n",
        "\n",
        "    print('Jacard Index : '+str(jacard))\n",
        "    print('Dice Coefficient : '+str(dice))\n",
        "    \n",
        "\n",
        "    fp = open('models/logfdbl.txt','a')\n",
        "    fp.write(str(jacard)+'\\n')\n",
        "    fp.close()\n",
        "\n",
        "    fp = open('models/bestfdbl.txt','r')\n",
        "    best = fp.read()\n",
        "    fp.close()\n",
        "\n",
        "    if(jacard>float(best)):\n",
        "        print('***********************************************')\n",
        "        print('Jacard Index improved from '+str(best)+' to '+str(jacard))\n",
        "        print('***********************************************')\n",
        "        fp = open('models/bestfdbl.txt','w')\n",
        "        fp.write(str(jacard))\n",
        "        fp.close()\n",
        "\n",
        "        saveModel(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "80IwnKtM9NHY"
      },
      "source": [
        "### Training the Model\n",
        "\n",
        "The model is trained and evaluated after each epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wlOOh0-nA05L",
        "colab": {}
      },
      "source": [
        "def trainStep(model, X_train, Y_train, X_test, Y_test, epochs, batchSize):\n",
        "\n",
        "    \n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        print('Epoch : {}'.format(epoch+1))\n",
        "        model.fit(x=X_train, y=Y_train, batch_size=batchSize, epochs=1, verbose=1)     \n",
        "\n",
        "        evaluateModel(model,X_test, Y_test,batchSize)\n",
        "\n",
        "    return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4wJ5V9AJ9Ygu"
      },
      "source": [
        "## Define Model, Train and Evaluate\n",
        "\n",
        "### The basic version:\n",
        "Loads the entire dataset and runs it for the given amount of epochs. \n",
        "Kindly change the names of the files as per requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GJqeuZPhDZSK",
        "colab": {}
      },
      "source": [
        "\n",
        "os.chdir(\"/content/drive/My Drive/CelebAMaskHQ/\")\n",
        "!ls\n",
        "model = MultiResUnet(height=192, width=256, n_channels=3)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, 'accuracy'])\n",
        "\n",
        "saveModel(model)\n",
        "\n",
        "fp = open('models/logfdbl.txt','w')\n",
        "fp.close()\n",
        "fp = open('models/bestfdbl.txt','w')\n",
        "fp.write('-1.0')\n",
        "fp.close()\n",
        "\n",
        "X_train,Y_train,X_test,Y_test = LoadData('X.npy','Y.npy')\n",
        "\n",
        "# NOTE : BATCH SIZE MAY NEED TO BE REDUCED IN ORDER FOR IT TO WORK ACROSS DEVICES\n",
        "trainStep(model, X_train, Y_train, X_test, Y_test, epochs=20, batchSize=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piBiSGI-UOWi",
        "colab_type": "text"
      },
      "source": [
        "### Improved Version \n",
        "This section specializes in using the split dataset mentioned above (currently accommodates the 3*10000 split used for training).\n",
        "\n",
        "It runs each split for the required amount of epochs, then deletes the variables in the memory in order to accomodate certain overload."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-ZwDOkBUNiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fd - full dataset\n",
        "os.chdir(\"/content/drive/My Drive/CelebAMaskHQ/\")\n",
        "!ls\n",
        "model = MultiResUnet(height=192, width=256, n_channels=3)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, 'accuracy'])\n",
        "\n",
        "saveModel(model)\n",
        "\n",
        "fp = open('models/logfdbl.txt','w')\n",
        "fp.close()\n",
        "fp = open('models/bestfdbl.txt','w')\n",
        "fp.write('-1.0')\n",
        "fp.close()\n",
        "\n",
        "for i in tqdm(range(1,4)):    \n",
        "    \n",
        "    print(\"Using dataset number :\"+str(i))\n",
        "    X_train,Y_train,X_test,Y_test = LoadData('X'+str(i)+'.npy','Y'+str(i)+'.npy')\n",
        "\n",
        "    # NOTE : BATCH SIZE MAY NEED TO BE REDUCED IN ORDER FOR IT TO WORK ACROSS DEVICES\n",
        "    trainStep(model, X_train, Y_train, X_test, Y_test, epochs=20, batchSize=10)\n",
        "    # Done in order to accomodate for RAM overload\n",
        "    del X_train\n",
        "    del Y_train\n",
        "    del X_test\n",
        "    del Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBUzbhDXxoYv",
        "colab_type": "text"
      },
      "source": [
        "#EXTRA : Pre processing of input files \n",
        "We pre process our input files in order to make it work with our current implementation.\n",
        "\n",
        "Note : This may cause Google drive timeouts due to the large size of the file, and show an I/O error. In this case just re run the snipppet again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN-6mafb5-Lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "  \n",
        "# Function to rename multiple files \n",
        "def renameFiles(folderName): \n",
        "      \n",
        "    for filename in os.listdir(folderName):\n",
        "        filenamenew = filename.split(\"_\"+folderName)\n",
        "        ipstring = filenamenew[0]\n",
        "        opstring = ipstring.lstrip('0')\n",
        "        if(opstring == ''):\n",
        "          opstring = '0'\n",
        "        dst =opstring + \"_\" + folderName + \".png\"\n",
        "        src =folderName +'/' + filename \n",
        "        dst =folderName + '/' + dst \n",
        "        print(\"Original \"+src)\n",
        "        print(\"Final \"+dst)\n",
        "          \n",
        "        # rename() function will \n",
        "        # rename all the files \n",
        "        os.rename(src, dst)\n",
        "    print(\"Done\")\n",
        "  \n",
        "# Driver Code \n",
        "if __name__ == '__main__': \n",
        "    os.chdir(\"/content/drive/My Drive/CelebAMaskHQ/\")  \n",
        "    !ls\n",
        "    # Calling main() function \n",
        "    # All completed\n",
        "    renameFiles(\"r_eye\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JJugdXUR7Qm",
        "colab_type": "text"
      },
      "source": [
        "# Demonstrations:\n",
        "\n",
        "Kindly check out [MultiResUNetCelebAMaskHQDemo.ipynb](https://colab.research.google.com/drive/10Vb4Ukv4xOG35bS1sUAVp2j2YA2L1xjZ) in order to utilise author built demo networks using the aforementioned architecture."
      ]
    }
  ]
}